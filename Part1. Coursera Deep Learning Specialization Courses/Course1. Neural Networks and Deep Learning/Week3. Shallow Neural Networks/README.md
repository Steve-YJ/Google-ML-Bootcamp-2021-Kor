## Week3. Shallow Neural Networks
> Build a neural network with one hidden layer, using forward propagation and backpropagation.

* Describe hidden units and hidden layers
* Use units with a non-linear activation function, such as tanh
* Implement forward and backward propagation
* Apply random initialization to your neural network
* Increase fluency in Deep Learning notations and Neural Network Representations
* Implement a 2-class classification neural network with a single hidden layer
* Compute the cross entropy loss

### Contents
* Shallow Neural Network
* Neural Networks Overview
* Neural Network Representation
* Computing a Neural Network's Output
* Vectorizing Across Multiple Examples
* Explanation for Vectorized Implementation
* Activation Functions
* Why do you need Non-Linear Activation Functions?
* Derivatives of Activation Functions
* Gradient Descent for Neural Networks
* Backpropagation Intuition (Optional)
* Random Initialization


### Lessons to learn
- [ ] Lecture - Shallow Neural Network
- [ ] Lecture Notes
- [ ] Quiz
- [x] Programming Assignment: Planar Data Classification with One Hidden Layer
<br>
