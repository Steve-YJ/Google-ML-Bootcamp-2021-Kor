# Overview

Tags: Deep Learning Specialization, Hyperparameter Tuning, Optimization, Regularization

# Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization

- Coursera Deep Learning Specialization Course2
- Course by Coursera and Andrew Ng

## Week1. Practical Aspects of Deep Learning

---

Discover and experiment with a variety of different initialization methods, apply L2 regularization and dropout to avoid model overfitting, then apply gradient checking to identify errors in a fraud detection model.

---

## 학습 목표

- Give examples of how different types of initializations can lead to different results
- Examine the importance of initialization in complex neural networks
- Explain the difference between train/dev/test sets
- Diagnose the bias and variance issues in your model
- Assess the right time and place for using regularization methods such as dropout or L2 regularization
- Explain Vanishing and Exploding gradients and how to deal with them Use gradient checking to verify the accuracy of your backpropagation implementation
- Apply zeros initialization, random initialization, and He initialization
- Apply regularization to a deep learning model

### Lectures

- Setting up your Machine Learning Application
- Connect with your Mentors and Fellow Learners on Discourse!
- Regularizing your Neural Network
- Setting Up your Optimization Problem
- Programming Assignments
    - Initialization - 3h
    - Regularization - 3h
    - Gradient Checking - 3h
